# app.py â€” ibon ç¥¨åˆ¸ç›£çœ‹ï¼ˆå« /check æ‰‹å‹•æŸ¥è©¢ã€/list éæ¿¾ã€/watch å»é‡ï¼‰
import base64
import hashlib
import hmac
import json
import logging
import os
import re
import secrets
import time
from typing import Dict, Tuple, Optional
from urllib.parse import urlparse, urljoin, parse_qsl, urlencode

import requests
from bs4 import BeautifulSoup
from flask import Flask, jsonify, request
from google.cloud import firestore

app = Flask(__name__)
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))

# ---------- åŸºç¤è¨­å®š ----------
db = firestore.Client()
LINE_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN") or os.environ.get("LINE_TOKEN")
LINE_SECRET = os.environ.get("LINE_CHANNEL_SECRET") or os.environ.get("LINE_SECRET")

# ç›¸å®¹ DEFAULT_INTERVAL èˆŠåç¨±
DEFAULT_PERIOD_SEC = int(
    (os.environ.get("DEFAULT_PERIOD_SEC") or os.environ.get("DEFAULT_INTERVAL") or "60")
)
MAX_TASKS_PER_TICK = int(os.environ.get("MAX_TASKS_PER_TICK", "25"))

PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT")
TASKS_QUEUE = os.environ.get("TASKS_QUEUE", "tick-queue")
TASKS_LOCATION = os.environ.get("TASKS_LOCATION", "asia-east1")
TASKS_SERVICE_ACCOUNT = os.environ.get("TASKS_SERVICE_ACCOUNT", "")
TASKS_TARGET_URL = os.environ.get("TASKS_TARGET_URL", "")
TICK_FANOUT = os.environ.get("TICK_FANOUT", "1") == "1"

UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/126.0 Safari/537.36"
)

# æ–‡å­—åµæ¸¬è¦å‰‡
_RE_QTY = re.compile(r"(ç©ºä½|å‰©é¤˜|å°šé¤˜|å°šæœ‰|å¯å”®|é¤˜ç¥¨|åé¡)[^\d]{0,5}(\d+)", re.I)
_RE_SOLDOUT = re.compile(r"(å”®ç½„|å®Œå”®|ç„¡ç¥¨|å·²å”®å®Œ|æš«ç„¡|æš«æ™‚ç„¡|å”®å®Œ|å·²å”®ç©º)", re.I)

HELP_TEXT = (
    "æˆ‘æ˜¯ç¥¨åˆ¸ç›£çœ‹æ©Ÿå™¨äºº ğŸ‘‹\n"
    "æŒ‡ä»¤ï¼š\n"
    "/start æˆ– /help ï¼ é¡¯ç¤ºé€™å€‹èªªæ˜\n"
    "/watch <URL> [ç§’] ï¼ é–‹å§‹ç›£çœ‹ï¼ˆæœ€å° 15 ç§’ï¼›åŒç¶²å€ä¸å¯é‡è¤‡å»ºç«‹ï¼Œå¸¶æ–°ç§’æ•¸æœƒæ›´æ–°æ—¢æœ‰ä»»å‹™ï¼‰\n"
    "/unwatch <ä»»å‹™ID> ï¼ åœç”¨ä»»å‹™\n"
    "/list ï¼ é¡¯ç¤ºå•Ÿç”¨ä¸­ä»»å‹™ï¼ˆ/list all çœ‹å…¨éƒ¨ï¼›/list off åªçœ‹åœç”¨ï¼‰\n"
    "/check <URL> ï¼ ç«‹åˆ»æ‰‹å‹•æŸ¥è©¢è©²é å‰©é¤˜ç¥¨æ•¸\n"
    "/checkid <ä»»å‹™ID> ï¼ ç«‹åˆ»æ‰‹å‹•æŸ¥è©¢è©²ä»»å‹™çš„ URL\n"
    "ä¹Ÿå¯ç›´æ¥è¼¸å…¥ã€ŒæŸ¥è©¢ã€æˆ– /check ä¸å¸¶åƒæ•¸ï¼ŒæœƒæŸ¥ä½ æœ€æ–°ä¸€ç­†å•Ÿç”¨ä¸­çš„ä»»å‹™"
)

# ---------- LINE åŸºæœ¬å‡½å¼ ----------
def _line_reply(reply_token: str, text: str) -> None:
    if not LINE_TOKEN or not reply_token:
        app.logger.warning("No LINE_TOKEN or reply_token; skip reply")
        return
    url = "https://api.line.me/v2/bot/message/reply"
    headers = {"Authorization": f"Bearer {LINE_TOKEN}", "Content-Type": "application/json"}
    body = {"replyToken": reply_token, "messages": [{"type": "text", "text": text[:4000]}]}
    try:
        r = requests.post(url, headers=headers, json=body, timeout=10)
        r.raise_for_status()
    except Exception as e:
        app.logger.exception(f"LINE reply failed: {e}")

def _line_reply_rich(reply_token: str, text: str, image_url: Optional[str] = None) -> None:
    if not LINE_TOKEN or not reply_token:
        app.logger.warning("No LINE_TOKEN or reply_token; skip reply")
        return
    url = "https://api.line.me/v2/bot/message/reply"
    headers = {"Authorization": f"Bearer {LINE_TOKEN}", "Content-Type": "application/json"}
    messages = []
    if image_url:
        messages.append({"type": "image","originalContentUrl": image_url,"previewImageUrl": image_url})
    messages.append({"type": "text", "text": text[:4000]})
    try:
        r = requests.post(url, headers=headers, json={"replyToken": reply_token, "messages": messages}, timeout=10)
        r.raise_for_status()
    except Exception as e:
        app.logger.exception(f"LINE reply (rich) failed: {e}")

def _line_push_rich(to: str, text: str, image_url: Optional[str] = None) -> None:
    if not LINE_TOKEN or not to:
        app.logger.warning("No LINE_TOKEN or target; skip push")
        return
    url = "https://api.line.me/v2/bot/message/push"
    headers = {"Authorization": f"Bearer {LINE_TOKEN}", "Content-Type": "application/json"}
    messages = []
    if image_url:
        messages.append({"type": "image","originalContentUrl": image_url,"previewImageUrl": image_url})
    messages.append({"type": "text", "text": text[:4000]})
    try:
        r = requests.post(url, headers=headers, json={"to": to, "messages": messages}, timeout=10)
        r.raise_for_status()
    except Exception as e:
        app.logger.exception(f"LINE push (rich) failed: {e}")

def _verify_line_signature(raw_body: bytes) -> bool:
    if not LINE_SECRET:
        return True
    sig = request.headers.get("X-Line-Signature", "")
    digest = hmac.new(LINE_SECRET.encode("utf-8"), raw_body, hashlib.sha256).digest()
    expected = base64.b64encode(digest).decode("utf-8")
    return hmac.compare_digest(sig, expected)

# ---------- ibon è§£æèˆ‡ç¶²å€æ­£è¦åŒ– ----------
def _req_session() -> requests.Session:
    s = requests.Session()
    s.headers.update({"User-Agent": UA, "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8", "Cache-Control": "no-cache"})
    return s

def resolve_ibon_orders_url(any_url: str) -> Optional[str]:
    u = urlparse(any_url)
    if "orders.ibon.com.tw" in u.netloc and "UTK0201" in u.path.upper():
        return any_url
    if "ticket.ibon.com.tw" in u.netloc:
        s = _req_session()
        r = s.get(any_url, timeout=15)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        a = soup.select_one('a[href*="orders.ibon.com.tw"][href*="UTK02"][href*="UTK0201"]')
        if a and a.get("href"):
            return urljoin(any_url, a["href"])
        for tag in soup.find_all(["a", "button"]):
            href = (tag.get("href") or tag.get("data-url") or "").strip()
            if "orders.ibon.com.tw" in href and "UTK0201" in href.upper():
                return urljoin(any_url, href)
    return None

def canonicalize_ibon_url(any_url: str) -> str:
    """å°‡ ibon ç¶²å€æ­£è¦åŒ–ç‚ºå”¯ä¸€ keyï¼šåƒ…ä¿ç•™ UTK0201 è¨‚è³¼é  + PERFORMANCE_ID/PRODUCT_ID"""
    url = resolve_ibon_orders_url(any_url) or any_url
    p = urlparse(url)
    host = p.netloc.lower()
    path = re.sub(r"/+", "/", p.path)
    pairs = parse_qsl(p.query, keep_blank_values=True)

    # ibon è¨‚è³¼é ï¼šåªç•™é—œéµåƒæ•¸
    keep = {"PERFORMANCE_ID", "PRODUCT_ID"}
    skip = {"STRITM", "UTM_SOURCE", "UTM_MEDIUM", "UTM_CAMPAIGN", "UTM_ID", "UTM_TERM", "UTM_CONTENT", "REF"}

    kept = []
    if "ibon.com.tw" in host and "UTK02" in path.upper():
        for k, v in pairs:
            ku = k.upper()
            if ku in keep:
                kept.append((ku, v.strip()))
        kept.sort()
        q = "&".join(f"{k}={v}" for k, v in kept)
    else:
        # ä¸€èˆ¬æƒ…æ³ï¼šæ’åº + å»é™¤è¿½è¹¤åƒæ•¸
        for k, v in pairs:
            if k.upper() in skip:
                continue
            kept.append((k, v))
        kept.sort()
        q = urlencode(kept, doseq=True)

    canon = f"https://{host}{path}"
    if q:
        canon += "?" + q
    return canon

def _first_text(*cands: Optional[str]) -> str:
    for c in cands:
        if c and str(c).strip():
            return str(c).strip()
    return ""

def _extract_activity_meta(soup: BeautifulSoup) -> Dict[str, str]:
    def find_label(labels):
        pat = re.compile("|".join(map(re.escape, labels)))
        for node in soup.find_all(text=pat):
            tag = node.parent
            if tag and tag.name in ("td", "th"):
                cells = [c.get_text(" ", strip=True) for c in tag.parent.find_all(["td", "th"])]
                for i, val in enumerate(cells):
                    if re.search(pat, val) and i + 1 < len(cells):
                        return cells[i + 1]
            text = tag.get_text(" ", strip=True) if tag else ""
            if re.search(pat, text):
                cleaned = pat.sub("", text).replace("ï¼š", "").strip()
                if cleaned:
                    return cleaned
            sib = tag.find_next_sibling() if tag else None
            if sib:
                t = sib.get_text(" ", strip=True)
                if t:
                    return t
        return ""
    title = _first_text(
        find_label(["æ´»å‹•åç¨±"]),
        soup.select_one('meta[property="og:title"]') and soup.select_one('meta[property="og:title"]').get("content"),
    )
    dt = _first_text(find_label(["æ´»å‹•æ™‚é–“", "æ´»å‹•æ—¥æœŸ"]))
    venue = _first_text(find_label(["æ´»å‹•åœ°é»", "åœ°é»"]))
    image = _first_text(
        soup.select_one('meta[property="og:image"]') and soup.select_one('meta[property="og:image"]').get("content"),
    )
    if not image:
        img = soup.find("img", src=re.compile(r"ActivityImage|azureedge|image/ActivityImage", re.I))
        if img and img.get("src"):
            image = urljoin("https://orders.ibon.com.tw/", img.get("src"))
    return {"title": title, "datetime": dt, "venue": venue, "image_url": image}

def parse_ibon_orders_static(html: str) -> Dict:
    soup = BeautifulSoup(html, "html.parser")
    sections: Dict[str, int] = {}
    total = 0
    soldout_hint = False

    # A) è¡¨æ ¼è§£æ
    for table in soup.find_all("table"):
        header_tr = None
        for tr in table.find_all("tr", recursive=True):
            if tr.find("th"):
                heads = [c.get_text(" ", strip=True) for c in tr.find_all(["th", "td"])]
                if any(h for h in heads if ("ç©ºä½" in h or "å‰©é¤˜" in h or "å¯å”®" in h)):
                    header_tr = tr
                    break
        if not header_tr:
            continue
        heads = [c.get_text(" ", strip=True) for c in header_tr.find_all(["th", "td"])]
        try:
            idx_qty = next(i for i, h in enumerate(heads) if ("ç©ºä½" in h or "å‰©é¤˜" in h or "å¯å”®" in h))
        except StopIteration:
            continue
        try:
            idx_area = next(i for i, h in enumerate(heads) if ("ç¥¨å€" in h or h == "å€" or "åº§ä½å€" in h))
        except StopIteration:
            idx_area = 1 if len(heads) > 1 else 0

        tr = header_tr.find_next_sibling("tr")
        while tr and tr.name == "tr":
            tds = tr.find_all("td")
            if len(tds) > max(idx_qty, idx_area):
                area = tds[idx_area].get_text(" ", strip=True)
                qty_text = tds[idx_qty].get_text(" ", strip=True)
                if _RE_SOLDOUT.search(qty_text):
                    soldout_hint = True
                m = re.search(r"(\d+)", qty_text)
                if m:
                    qty = int(m.group(1))
                    if qty > 0:
                        area = re.sub(r"\s+", "", area) or "æœªå‘½åå€"
                        sections[area] = sections.get(area, 0) + qty
                        total += qty
            tr = tr.find_next_sibling("tr")
        if total > 0:
            break

    # B) é—œéµå­—æƒæ
    if total == 0:
        candidates = soup.select("tr, li, div, p, span")
        for node in candidates:
            txt = node.get_text(" ", strip=True)
            if not txt:
                continue
            if _RE_SOLDOUT.search(txt):
                soldout_hint = True
            m = _RE_QTY.search(txt)
            if not m:
                continue
            qty = int(m.group(2))
            if qty <= 0:
                continue
            key = "æœªå‘½åå€"
            tr = node if node.name == "tr" else node.find_parent("tr")
            if tr:
                cells = [c.get_text(" ", strip=True) for c in tr.find_all(["td", "th"])]
                for c in cells:
                    if re.search(r"(å€|çœ‹å°|å…§é‡|å¤–é‡|åº§|æ¨“|å±¤)", c):
                        key = re.sub(r"\s+", "", c)
                        break
            sections[key] = sections.get(key, 0) + qty
            total += qty

    return {"sections": sections, "total": total, "soldout": (total == 0 and soldout_hint), "soup": soup}

def check_ibon(any_url: str) -> Tuple[bool, str, str, Dict[str, str]]:
    orders_url = resolve_ibon_orders_url(any_url)
    if not orders_url:
        return False, "æ‰¾ä¸åˆ° ibon ä¸‹å–®é ï¼ˆUTK0201ï¼‰ã€‚å¯èƒ½å°šæœªé–‹è³£æˆ–æŒ‰éˆ•æœªé¡¯ç¤ºã€‚", "NA", {}
    s = _req_session()
    r = s.get(orders_url, timeout=15)
    r.raise_for_status()

    parsed = parse_ibon_orders_static(r.text)
    meta = _extract_activity_meta(parsed["soup"])
    title = meta.get("title") or "æ´»å‹•è³‡è¨Š"
    venue = meta.get("venue")
    dt = meta.get("datetime")
    img = meta.get("image_url")

    prefix_lines = [f"ğŸ« {title}"]
    if venue: prefix_lines.append(f"åœ°é»ï¼š{venue}")
    if dt: prefix_lines.append(f"æ—¥æœŸï¼š{dt}")
    prefix = "\n".join(prefix_lines) + "\n\n"

    if parsed["total"] > 0:
        parts = [f"{k}: {v} å¼µ" for k, v in sorted(parsed["sections"].items(), key=lambda kv: (-kv[1], kv[0]))]
        msg = prefix + "âœ… ç›£çœ‹çµæœï¼šç›®å‰å¯å”®\n" + "\n".join(parts) + f"\nåˆè¨ˆï¼š{parsed['total']} å¼µ\n{orders_url}"
        sig = hashlib.md5(("|" + "|".join(parts)).encode()).hexdigest()
        return True, msg, sig, {"image_url": img}
    if parsed.get("soldout"):
        msg = prefix + f"ç›®å‰é¡¯ç¤ºå®Œå”®/ç„¡ç¥¨\n{orders_url}"
        sig = hashlib.md5("soldout".encode()).hexdigest()
        return True, msg, sig, {"image_url": img}

    return False, prefix + "æš«æ™‚è®€ä¸åˆ°å‰©é¤˜æ•¸ï¼ˆå¯èƒ½ç‚ºå‹•æ…‹è¼‰å…¥ï¼‰ã€‚\n" + orders_url, "NA", {"image_url": img}

# ---------- Webhook ----------
def _get_target_id(src: dict) -> str:
    return src.get("userId") or src.get("groupId") or src.get("roomId") or ""

@app.post("/webhook")
def webhook():
    raw = request.get_data()
    if not _verify_line_signature(raw):
        app.logger.error("Invalid LINE signature")
        return "bad signature", 400

    body = request.get_json(silent=True) or {}
    events = body.get("events", [])

    for ev in events:
        etype = ev.get("type")
        if etype in ("follow", "join"):
            _line_reply(ev.get("replyToken"), HELP_TEXT); continue
        if etype != "message": continue

        msg = ev.get("message", {})
        if msg.get("type") != "text": continue

        text = (msg.get("text") or "").strip()
        reply_token = ev.get("replyToken")
        src = ev.get("source", {})
        low = text.lower()

        if low in ("/start", "start", "/help", "help", "ï¼Ÿ"):
            _line_reply(reply_token, HELP_TEXT); continue

        # ---- æ‰‹å‹•æŸ¥è©¢ ----
        if low.startswith("/checkid"):
            parts = text.split()
            if len(parts) < 2:
                _line_reply(reply_token, "ç”¨æ³•ï¼š/checkid <ä»»å‹™ID>"); continue
            tid = parts[1].strip()
            docref = db.collection("watches").document(tid)
            doc = docref.get()
            if not doc.exists:
                _line_reply(reply_token, f"æ‰¾ä¸åˆ°ä»»å‹™ {tid}"); continue
            task = doc.to_dict()
            ok, msg_out, _sig, meta = check_ibon(task.get("url", ""))
            _line_reply_rich(reply_token, msg_out, (meta or {}).get("image_url")); continue

        if low.startswith("/check") or text == "æŸ¥è©¢":
            parts = text.split()
            url = None
            if len(parts) >= 2 and parts[1].startswith("http"):
                url = parts[1]
            if not url:
                target_id = _get_target_id(src)
                q = (db.collection("watches")
                     .where("targetId", "==", target_id)
                     .where("active", "==", True)
                     .order_by("createdAt", direction=firestore.Query.DESCENDING)
                     .limit(1))
                docs = list(q.stream())
                if docs: url = docs[0].to_dict().get("url")
            if not url:
                _line_reply(reply_token, "ç”¨æ³•ï¼š/check <ç¥¨åˆ¸ç¶²å€>\næˆ–å…ˆç”¨ /watch å»ºç«‹ä»»å‹™å¾Œè¼¸å…¥ã€ŒæŸ¥è©¢ã€"); continue
            ok, msg_out, _sig, meta = check_ibon(url)
            _line_reply_rich(reply_token, msg_out, (meta or {}).get("image_url")); continue
        # -------------------

        # ---- watchï¼šåŠ å…¥å»é‡/å¾©ç”¨/æ›´æ–° period ----
        if low.startswith("/watch"):
            parts = text.split()
            if len(parts) < 2:
                _line_reply(reply_token, "ç”¨æ³•ï¼š/watch <ç¥¨åˆ¸ç¶²å€> [ç§’]\nå¯è²¼æ´»å‹•é æˆ– orders å…§é "); continue

            raw_url = parts[1]
            period = DEFAULT_PERIOD_SEC
            if len(parts) >= 3:
                try:
                    p = int(parts[2]); period = max(15, min(3600, p))
                except Exception: pass

            target_id = _get_target_id(src)
            target_type = "user" if src.get("userId") else ("group" if src.get("groupId") else "room")
            url_canon = canonicalize_ibon_url(raw_url)

            # 1) å˜—è©¦ç”¨ urlCanon ç²¾æº–æŸ¥è©¢ï¼ˆè‹¥éœ€è¦ç´¢å¼•æœƒè‡ªå‹•é™ç´šï¼‰
            existing = None
            try:
                q0 = (db.collection("watches")
                      .where("targetId", "==", target_id)
                      .where("urlCanon", "==", url_canon)
                      .limit(1))
                docs0 = list(q0.stream())
                existing = docs0[0] if docs0 else None
            except Exception as e:
                app.logger.warning(f"/watch query by urlCanon failed, fallback scan: {e}")

            # 2) å¾Œå‚™ï¼šæƒæè¿‘æœŸä»»å‹™æ¯”å°ï¼ˆé¿å…ç¼ºç´¢å¼•ï¼‰
            if not existing:
                q1 = (db.collection("watches")
                      .where("targetId", "==", target_id)
                      .order_by("createdAt", direction=firestore.Query.DESCENDING)
                      .limit(50))
                for d in q1.stream():
                    x = d.to_dict()
                    cand = x.get("urlCanon") or canonicalize_ibon_url(x.get("url", ""))
                    if cand == url_canon:
                        existing = d; break

            now = int(time.time())
            if existing:
                data = existing.to_dict()
                if data.get("active", True):
                    # å·²åœ¨ç›£çœ‹ï¼šæ›´æ–° periodï¼ˆè‹¥æœ‰å¸¶æ–°å€¼ï¼‰
                    if int(data.get("periodSec", DEFAULT_PERIOD_SEC)) != period:
                        existing.reference.update({"periodSec": period, "nextCheckAt": now})
                        _line_reply(reply_token, f"æ­¤ç¶²å€å·²åœ¨ç›£çœ‹ âœ…\nä»»å‹™IDï¼š{existing.id}\nå·²æ›´æ–°ç‚ºæ¯ {period} ç§’æª¢æŸ¥\nURLï¼š{data.get('url')}")
                    else:
                        _line_reply(reply_token, f"æ­¤ç¶²å€å·²åœ¨ç›£çœ‹ âœ…\nä»»å‹™IDï¼š{existing.id}\næ¯ {data.get('periodSec', DEFAULT_PERIOD_SEC)} ç§’æª¢æŸ¥\nURLï¼š{data.get('url')}")
                else:
                    # å­˜åœ¨ä½†åœç”¨ â†’ ç›´æ¥é‡æ–°å•Ÿç”¨
                    existing.reference.update({"active": True, "periodSec": period, "nextCheckAt": now})
                    _line_reply(reply_token, f"å·²é‡æ–°å•Ÿç”¨ âœ…\nä»»å‹™IDï¼š{existing.id}\næ¯ {period} ç§’æª¢æŸ¥\nURLï¼š{data.get('url')}")
                continue

            # 3) å®Œå…¨æ–°ä»»å‹™ â†’ å»ºç«‹
            task_id = secrets.token_urlsafe(4)
            db.collection("watches").document(task_id).set({
                "url": raw_url,
                "urlCanon": url_canon,
                "targetType": target_type,
                "targetId": target_id,
                "periodSec": period,
                "nextCheckAt": now,     # ç«‹åˆ» due
                "lastSig": None,
                "active": True,
                "createdAt": now,
            })
            _line_reply(reply_token, f"å·²é–‹å§‹ç›£çœ‹ âœ…\nä»»å‹™IDï¼š{task_id}\næ¯ {period} ç§’æª¢æŸ¥ä¸€æ¬¡\nURLï¼š{raw_url}")
            continue
        # -------------------

        if low.startswith("/unwatch"):
            parts = text.split()
            if len(parts) < 2:
                _line_reply(reply_token, "ç”¨æ³•ï¼š/unwatch <ä»»å‹™ID>"); continue
            tid = parts[1]
            doc = db.collection("watches").document(tid)
            if doc.get().exists:
                doc.update({"active": False})
                _line_reply(reply_token, f"ä»»å‹™ {tid} å·²åœç”¨")
            else:
                _line_reply(reply_token, f"æ‰¾ä¸åˆ°ä»»å‹™ {tid}")
            continue

        if low.startswith("/list"):
            mode = "on"  # é è¨­åªåˆ—å•Ÿç”¨ä¸­
            if len(text.split()) >= 2:
                opt = text.split()[1].lower()
                if opt in ("all", "-a", "--all"): mode = "all"
                elif opt in ("off", "--off"): mode = "off"

            target_id = _get_target_id(src)
            q = db.collection("watches").where("targetId", "==", target_id)

            if mode == "on":
                q = q.where("active", "==", True)
            elif mode == "off":
                q = q.where("active", "==", False)

            q = q.order_by("createdAt", direction=firestore.Query.DESCENDING).limit(20)
            docs = list(q.stream())
            if not docs:
                _line_reply(reply_token, "ç›®å‰æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ä»»å‹™" + ("" if mode=="on" else f"ï¼ˆ{mode}ï¼‰"))
            else:
                lines = []
                for d in docs:
                    x = d.to_dict()
                    flag = "å•Ÿç”¨" if x.get("active") else "åœç”¨"
                    if mode == "on" and not x.get("active"):  # ä¿éšªå†éæ¿¾ä¸€æ¬¡
                        continue
                    lines.append(f"{d.id}ï½œ{flag}ï½œ{x.get('periodSec', 60)}s\n{x.get('url')}")
                if not lines:
                    _line_reply(reply_token, "ç›®å‰æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ä»»å‹™")
                else:
                    title = "ä½ çš„ä»»å‹™ï¼š" if mode=="on" else ("ä½ çš„ä»»å‹™ï¼ˆå…¨éƒ¨ï¼‰ï¼š" if mode=="all" else "ä½ çš„ä»»å‹™ï¼ˆåœç”¨ï¼‰ï¼š")
                    _line_reply(reply_token, title + "\n" + "\n\n".join(lines))
            continue

        _line_reply(reply_token, HELP_TEXT)

    return "OK"

# ---------- 15 ç§’æ‰‡å‡ºï¼šCloud Tasks ----------
def enqueue_tick_runs(delays=(0, 15, 30, 45)) -> int:
    try:
        from google.cloud import tasks_v2
        from google.protobuf import timestamp_pb2
    except Exception as e:
        app.logger.warning(f"[fanout] cloud-tasks lib missing, run once. {e}")
        return 0

    if not (PROJECT_ID and TASKS_QUEUE and TASKS_LOCATION and TASKS_SERVICE_ACCOUNT and TASKS_TARGET_URL):
        app.logger.warning("[fanout] env incomplete; run once instead.")
        return 0

    client = tasks_v2.CloudTasksClient()
    parent = client.queue_path(PROJECT_ID, TASKS_LOCATION, TASKS_QUEUE)
    created = 0

    for d in delays:
        ts = timestamp_pb2.Timestamp()
        ts.FromSeconds(int(time.time()) + int(d))
        task = {
            "http_request": {
                "http_method": tasks_v2.HttpMethod.GET,
                "url": f"{TASKS_TARGET_URL}/cron/tick?mode=run",
                "headers": {"User-Agent": "Cloud-Tasks", "X-From-Tasks": "1"},
                "oidc_token": {"service_account_email": TASKS_SERVICE_ACCOUNT, "audience": TASKS_TARGET_URL},
            },
            "schedule_time": ts
        }
        try:
            client.create_task(request={"parent": parent, "task": task}); created += 1
        except Exception as e:
            app.logger.exception(f"[fanout] create_task failed (delay={d}): {e}")

    return created

def do_tick():
    now = int(time.time())
    q = (db.collection("watches")
         .where("active", "==", True)
         .where("nextCheckAt", "<=", now)
         .limit(MAX_TASKS_PER_TICK))
    try:
        docs = list(q.stream())
    except Exception as e:
        app.logger.exception(f"[tick] Firestore query failed: {e}")
        return jsonify({"ok": False, "stage": "query", "error": str(e)}), 200

    processed, errors = 0, []
    for d in docs:
        task = d.to_dict()
        try:
            ok, msg, sig, meta = check_ibon(task["url"])
            if ok and sig != task.get("lastSig"):
                _line_push_rich(task["targetId"], msg, (meta or {}).get("image_url"))
                d.reference.update({"lastSig": sig})
        except Exception as e:
            app.logger.exception(f"[tick] task {d.id} failed: {e}")
            errors.append(f"{d.id}:{type(e).__name__}")
        finally:
            period = int(task.get("periodSec", DEFAULT_PERIOD_SEC))
            d.reference.update({"nextCheckAt": now + max(15, period)})
            processed += 1

    return jsonify({"ok": True, "processed": processed, "due": len(docs), "errors": errors, "ts": now}), 200

@app.get("/cron/tick")
def cron_tick():
    if request.args.get("mode") == "run" or request.headers.get("X-From-Tasks") == "1":
        return do_tick()
    if TICK_FANOUT:
        n = enqueue_tick_runs((0, 15, 30, 45))
        if n > 0:
            return jsonify({"ok": True, "fanout": n}), 200
    return do_tick()

@app.get("/healthz")
def healthz():
    return "ok", 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", "8080")))