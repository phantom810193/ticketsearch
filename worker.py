# worker.py â€” ä½å®…ç¶²è·¯è¼ªè©¢æ¨æ’­ï¼ˆFirestore + LINE v3ï¼‰
import os
import sys
import time
import random
import logging
import hashlib
import re
import unicodedata
from typing import Tuple, List, Dict
from urllib.parse import urlparse

import requests
try:
    import cloudscraper  # å¯é¸ï¼šè¼ƒèƒ½è™•ç†éƒ¨åˆ† Cloudflare
except ImportError:
    cloudscraper = None

from bs4 import BeautifulSoup

# ========= Loggingï¼ˆé¿å… Windows ä¸»æ§å°ç·¨ç¢¼å•é¡Œï¼‰=========
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s: %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True,
)
logger = logging.getLogger("tixworker")
logger.setLevel(logging.INFO)
logger.handlers.clear()
logger.addHandler(logging.StreamHandler(sys.stdout))
logger.propagate = False

def _safe(s: str) -> str:
    """é¿å… console cp950 ç­‰ç·¨ç¢¼å•é¡Œï¼Œå»æ‰ç„¡æ³•åˆ—å°çš„å­—å…ƒã€‚"""
    try:
        return s.encode(sys.stdout.encoding or "utf-8", errors="ignore").decode(sys.stdout.encoding or "utf-8", errors="ignore")
    except Exception:
        return s

# ========= ç’°å¢ƒè®Šæ•¸ =========
LINE_CHANNEL_ACCESS_TOKEN = (os.getenv("LINE_CHANNEL_ACCESS_TOKEN") or "").strip()
if not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ LINE_CHANNEL_ACCESS_TOKENï¼ˆç”¨æ–¼æ¨æ’­ï¼‰")

DEFAULT_INTERVAL = int(os.getenv("DEFAULT_INTERVAL", "15"))   # é è¨­ä»»å‹™è¼ªè©¢ç§’æ•¸ä¸Šé™ä¸‹é™æœƒåœ¨ç¨‹å¼å†æ§
WORKER_IDLE_SEC = float(os.getenv("WORKER_IDLE_SEC", "1.5"))  # æ¯è¼ªé–’ç½®ç§’æ•¸
MAX_RETRY = int(os.getenv("FETCH_MAX_RETRY", "2"))
REQUEST_TIMEOUT = int(os.getenv("REQUEST_TIMEOUT", "15"))
USER_AGENT = os.getenv("USER_AGENT") or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126 Safari/537.36"
COOKIES_RAW = os.getenv("TIXCRAFT_COOKIES", "").strip()  # å¯é¸ï¼š"name=value; name2=value2"

# ========= LINE v3ï¼ˆåƒ…æ¨æ’­ç”¨ï¼‰=========
from linebot.v3.messaging import (
    Configuration, ApiClient, MessagingApi,
    PushMessageRequest, TextMessage as V3TextMessage, ApiException
)
configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
api_client = ApiClient(configuration)
messaging_api = MessagingApi(api_client)

def push(user_id: str, message: str):
    """æ¨æ’­çµ¦ä½¿ç”¨è€…ï¼šlog ä¸å° emojiï¼Œé¿å… Windows ç·¨ç¢¼éŒ¯èª¤ã€‚"""
    try:
        messaging_api.push_message(
            PushMessageRequest(
                to=user_id,
                messages=[V3TextMessage(text=message)]
            )
        )
        logger.info("[push] sent to %s: %s", user_id, _safe(message[:80].replace("\n", " ")))
    except ApiException as e:
        logger.error("[push] LINE API error: %s", e)

# ========= Firestore =========
from google.cloud import firestore
from google.cloud.firestore_v1 import FieldFilter

PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT") or os.getenv("GCP_PROJECT") or "ticketsearch-470701"
db = firestore.Client(project=PROJECT_ID)
TASKS = db.collection("tasks")
print("[ENV] PROJECT_ID =", PROJECT_ID)

def _now_ts() -> int:
    return int(time.time())

def all_active_tasks() -> List[Dict]:
    # ä½¿ç”¨ FieldFilter é¿å… where çš„è­¦å‘Š
    docs = TASKS.where(filter=FieldFilter("is_active", "==", True)).stream()
    return [d.to_dict() for d in docs]

def update_after_check(tid: str, snapshot: str):
    TASKS.document(tid).update({"last_snapshot": snapshot, "last_checked": _now_ts()})

# ========= å–é é¢ =========
def _cookies_dict(raw: str) -> Dict[str, str]:
    if not raw:
        return {}
    pairs = [p.strip() for p in raw.split(";") if p.strip()]
    out = {}
    for p in pairs:
        if "=" in p:
            k, v = p.split("=", 1)
            out[k.strip()] = v.strip()
    return out

def _make_session():
    if cloudscraper:
        return cloudscraper.create_scraper(browser={"browser": "chrome", "platform": "windows"})
    s = requests.Session()
    return s

def fetch_html(url: str, timeout: int = REQUEST_TIMEOUT, retries: int = MAX_RETRY) -> str:
    """ä»¥ä¸€èˆ¬/residential ç’°å¢ƒå­˜å–ï¼Œåµæ¸¬ 403/5xx é‡è©¦ã€‚"""
    sess = _make_session()
    headers = {
        "User-Agent": USER_AGENT,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
        "Cache-Control": "no-cache",
        "Pragma": "no-cache",
        "Connection": "keep-alive",
        "DNT": "1",
        "Referer": f"{urlparse(url).scheme}://{urlparse(url).hostname}/",
    }
    cookies = _cookies_dict(COOKIES_RAW)

    last_exc = None
    for attempt in range(retries + 1):
        try:
            r = sess.get(url, headers=headers, cookies=cookies or None, timeout=timeout)
            # æŸäº›ç¶²ç«™å° 403/429/503 æ‰éœ€è¦é‡è©¦
            if r.status_code in (403, 429, 503):
                raise requests.HTTPError(f"{r.status_code} for {url}", response=r)
            r.raise_for_status()
            # å–æ–‡å­—
            return r.text
        except Exception as e:
            last_exc = e
            code = getattr(getattr(e, "response", None), "status_code", None)
            logger.warning("[fetch] attempt=%s code=%s url=%s", attempt, code, url)
            time.sleep(0.8 + attempt * 0.8 * random.random())
    # å…¨éƒ¨å¤±æ•—
    raise last_exc

# ========= æ–‡å­—æ­£è¦åŒ– & ç¥¨åˆ¸åµæ¸¬ =========
SOLDOUT_KWS = ["å”®å®Œ", "å®Œå”®", "å·²å”®å®Œ", "å·²å”®ç½„", "å·²ç„¡ç¥¨", "sold out", "soldout"]
TICKET_KWS  = ["ç«‹å³è³¼ç¥¨", "è³¼ç¥¨", "åŠ å…¥è³¼ç‰©è»Š", "é¸æ“‡åº§ä½", "å‰©é¤˜", "å¯å”®", "å°šæœ‰", "é–‹è³£", "tickets"]

def normalize_text(s: str) -> str:
    s = unicodedata.normalize("NFKC", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def extract_snapshot_and_ticket(html: str) -> Tuple[str, bool, List[str]]:
    """
    èƒå–é é¢æ–‡å­—å¿«ç…§èˆ‡æ˜¯å¦åˆ¤å®šã€Œæœ‰ç¥¨ã€ã€‚
    å¦å¤–å‚³å› area_hitsï¼šä¾‹å¦‚ ['Aå€ å‰©é¤˜ 12', 'Bå€ å°šæœ‰ 5']ï¼Œå¯æ”¾é€²æ¨æ’­è¨Šæ¯ã€‚
    """
    soup = BeautifulSoup(html, "html.parser")
    for tag in soup(["script", "style", "noscript"]):
        tag.decompose()

    text = normalize_text(soup.get_text(" ", strip=True))
    low = text.lower()

    # é—œéµå­—åˆ¤æ–·ï¼ˆä¸åŒ…å« soldoutï¼‰
    has_kw = any(kw.lower() in low for kw in TICKET_KWS)
    is_soldout = any(kw.lower() in low for kw in SOLDOUT_KWS)
    has_ticket = has_kw and not is_soldout

    # é€²ä¸€æ­¥æŠ“å„å€ã€Œå‰©é¤˜/å°šæœ‰/å¯å”® æ•¸å­—ã€
    area_hits = []
    # ç¯„ä¾‹ï¼šAå€ å‰©é¤˜ 12ã€æ–æ»¾å€ å°šæœ‰10ã€B3 å¯å”® 3
    for m in re.finditer(r"([A-Za-z0-9\u4e00-\u9fff]{1,12}å€)\s*(?:åº§ä½|é–€ç¥¨|ç¥¨)?\s*(å‰©é¤˜|å°šæœ‰|å¯å”®)\s*(\d+)", text):
        g = f"{m.group(1)} {m.group(2)} {m.group(3)}"
        if g not in area_hits:
            area_hits.append(g)
    # è£œæŠ“ã€Œç«‹å³è³¼ç¥¨/é¸æ“‡åº§ä½/åŠ å…¥è³¼ç‰©è»Šã€çš„æŒ‰éˆ•æ–‡å­—
    important_bits = []
    for btn in soup.find_all(["a", "button"]):
        t = btn.get_text(" ", strip=True)
        if t:
            important_bits.append(normalize_text(t))
    snapshot = text + "\n\nBTN:" + "|".join(important_bits[:60])

    # å¦‚æœè§£æåˆ° area_hitsï¼Œå‰‡ä¸€å®šè¦–ç‚º has_ticket
    if area_hits:
        has_ticket = True

    return snapshot, has_ticket, area_hits

# ========= ä¸»è¿´åœˆ =========
def _clamp_interval(v: int) -> int:
    try:
        v = int(v)
    except Exception:
        v = DEFAULT_INTERVAL
    return max(5, min(300, v))

def run_once() -> int:
    """åŸ·è¡Œä¸€è¼ªï¼šæƒæåˆ°æœŸçš„ä»»å‹™ï¼Œå›å‚³å·²æª¢æŸ¥æ•¸é‡ã€‚"""
    tasks = all_active_tasks()
    random.shuffle(tasks)

    logger.info("æŠ“åˆ° %d å€‹æ´»èºä»»å‹™", len(tasks))
    checked = 0
    now = _now_ts()

    for t in tasks:
        try:
            last_checked = int(t.get("last_checked", 0) or 0)
            interval_sec = _clamp_interval(t.get("interval_sec", DEFAULT_INTERVAL))
            if (now - last_checked) < interval_sec:
                continue

            tid = t.get("tid")
            url = t.get("url")
            user_id = t.get("user_id")
            logger.info("â†’ æª¢æŸ¥ task#%s æ¯ %ss url=%s", tid, interval_sec, url)

            html = fetch_html(url)
            snapshot, has_ticket, area_hits = extract_snapshot_and_ticket(html)

            new_hash = hashlib.sha256(snapshot.encode("utf-8")).hexdigest()
            old_hash = hashlib.sha256((t.get("last_snapshot") or "").encode("utf-8")).hexdigest()
            first_run = not bool(t.get("last_snapshot"))

            update_after_check(tid, snapshot)
            changed = (new_hash != old_hash)

            logger.info("[check] task#%s has_ticket=%s first_run=%s changed=%s", tid, has_ticket, first_run, changed)

            # == é€šçŸ¥æ¢ä»¶ ==
            # 1) æœ‰ç¥¨ ä¸” (ç¬¬ä¸€æ¬¡ | å…§å®¹è®Šæ›´) å°±æ¨æ’­
            if has_ticket and (first_run or changed):
                detail = f"\n" + "\n".join(f"ãƒ»{h}" for h in area_hits[:10]) if area_hits else ""
                # æ¨æ’­æ–‡å­—å¯ä»¥åŒ…å« emojiï¼Œä¸å¯«å…¥ log
                msg = f"ğŸ‰ ç–‘ä¼¼æœ‰ç¥¨é‡‹å‡ºï¼\nä»»å‹™#{tid}\n{url}{detail}\nï¼ˆå»ºè­°ç«‹åˆ»é»é€²å»æª¢æŸ¥èˆ‡è³¼è²·ï¼‰"
                push(user_id, msg)

            checked += 1
            time.sleep(random.uniform(0.2, 0.6))

        except requests.HTTPError as he:
            code = getattr(getattr(he, "response", None), "status_code", None)
            logger.error("[check] HTTPError %s for %s", code, t.get("url"))
        except Exception as e:
            logger.exception("[check] task#%s error: %s", t.get("tid"), e)

    return checked

def main():
    logger.info("%s", _safe("worker å•Ÿå‹•ï¼ˆä½å®…ç¶²è·¯æ¨¡å¼ï¼‰"))
    try:
        while True:
            n = run_once()
            # æ²’ä»»å‹™å°±ç¨å¾®ä¼‘æ¯ä¹…ä¸€é»
            time.sleep(WORKER_IDLE_SEC if n else max(WORKER_IDLE_SEC, 2.5))
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–·è¨Šè™Ÿï¼ŒçµæŸã€‚")

if __name__ == "__main__":
    main()